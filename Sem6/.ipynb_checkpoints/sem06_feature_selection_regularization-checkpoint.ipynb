{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тех, кому интересно векторное дифференцирование и почему в линейной регрессии оптимальная оценка весов равна $w = \\left(X^TX\\right)^{-1}X^Ty$:\n",
    "\n",
    "- http://www.machinelearning.ru/wiki/images/5/50/MOMO17_Seminar2.pdf\n",
    "- https://github.com/esokolov/ml-course-hse/blob/master/2017-fall/seminars/sem02-linregr-part1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/esokolov/ml-minor-hse/blob/master/colloquium-2017/colloquium_minor_problems_linear.pdf\n",
    "\n",
    "Задачи 1, 3, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы поработаем с данными о сообществах в США. Описание датасета:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/communities+and+crime\n",
    "\n",
    "Датасет на кэггле (в формате .csv):\n",
    "\n",
    "https://www.kaggle.com/kkanda/communities%20and%20crime%20unnormalized%20data%20set\n",
    "\n",
    "Будем предсказывать количество насильственных преступлений относительно численности населения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('crimedata.csv', na_values=[\"?\"])\n",
    "# будем работать не со всеми колонками\n",
    "requiredColumns = [5, 6] + list(range(11,26)) + list(range(32, 103)) + [145]\n",
    "data = data[data.columns[requiredColumns]]\n",
    "# некоторые значения целевой переменной пропущены\n",
    "X = data.loc[data['ViolentCrimesPerPop'].notnull(), :].drop('ViolentCrimesPerPop', axis=1)\n",
    "y = data['ViolentCrimesPerPop'][X.index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим линейную регрессию и выведем качество по метрике MSE на обучающей и тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 119935.90613769474\n",
      "Test: 206978.88438445536\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 88)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим регуляризатор и посмотрим, изменилось ли качество. В качестве метода регуляризации используем Ridge ($L_2$-регуляризация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 120349.55028715706\n",
      "Test: 206958.22395453055\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(5.0).fit(X_train,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.61892346e-03, -9.43009110e+01,  1.36067510e+01, -3.13380670e+01,\n",
       "       -8.15482713e-02, -1.69455128e+01, -2.42730375e-03,  1.53013232e+00,\n",
       "       -1.39193248e-02, -7.72112833e+00,  2.28112354e+01, -5.65708295e+00,\n",
       "        9.34751364e+00,  2.06969566e-01, -7.43413626e+00,  9.65856476e-03,\n",
       "        4.38030290e-03,  4.79754625e-03, -4.46469212e+00, -1.60907140e+01,\n",
       "        8.82778012e+00, -5.06734503e-01, -1.42198055e+00,  8.17551991e+00,\n",
       "       -3.87048268e+00, -3.54209213e+00,  4.48758304e+00,  9.30645715e+00,\n",
       "        1.73644996e+02,  1.18220766e+01,  1.51120836e+02, -3.29613007e+02,\n",
       "       -1.35343395e+02,  6.95380108e-01, -2.38369008e+01,  2.77038981e+00,\n",
       "        3.82248925e-01,  4.38813358e+00, -1.06410851e+01, -4.92294176e-03,\n",
       "        4.14031827e+01, -1.16206866e-03,  1.18568968e+00,  1.75418465e+00,\n",
       "       -3.68283678e+00,  1.59679443e+00, -8.42180230e+00, -3.79703897e+01,\n",
       "        4.74076990e+01, -2.50768374e+01, -2.88246410e-01, -3.65633234e+01,\n",
       "        1.89516080e+01, -4.53336736e+01,  6.82698598e+02,  1.04478671e+02,\n",
       "       -3.28575414e+02, -3.14364068e+01,  2.74053494e+01,  5.12336432e+00,\n",
       "        6.91580764e+01,  1.98267157e-02, -6.12133638e-01,  2.65335065e+01,\n",
       "        1.00704633e+01, -1.58621594e+00,  2.24025322e+00,  7.38288450e+00,\n",
       "       -3.13915504e+01, -9.77857270e-05,  5.01970945e-05, -3.48059432e-04,\n",
       "       -2.50225916e-04, -5.26610456e-01, -5.16564774e-01, -4.10464090e-01,\n",
       "        1.16146366e-01,  1.46167357e+00, -3.04019816e-01,  2.43792841e+00,\n",
       "       -3.65615457e+01,  1.41488917e-01,  2.88800603e-01,  1.77464865e+01,\n",
       "        5.96587698e-01,  1.98257510e+00, -1.36380442e-01, -1.85303461e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что изменится при нормировании признаков? Попробуем MinMaxScaler. Есть ли разница? Влияет ли нормирование на качество линейной регрессии? А на качество регуляризованной? Почему так?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train_scaled = pd.DataFrame(data=sc.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(data=sc.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 119939.91932934783\n",
      "Test: 207079.3179082665\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train_scaled,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_scaled))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 131185.03859170148\n",
      "Test: 171004.31076565196\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_scaled,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_scaled))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 High/low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезны ли признаки, имеющие высокую дисперсию? А низкую?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numbUrban                1.536967e+10\n",
       "population               1.501308e+10\n",
       "OwnOccHiQuart            1.047632e+10\n",
       "OwnOccMedVal             7.298749e+09\n",
       "OwnOccLowQuart           4.865597e+09\n",
       "OwnOccQrange             1.578016e+09\n",
       "NumImmig                 1.375814e+09\n",
       "NumUnderPov              4.807284e+08\n",
       "medFamInc                2.102099e+08\n",
       "medIncome                1.861763e+08\n",
       "NumKidsBornNeverMar      5.625722e+07\n",
       "perCapInc                4.064100e+07\n",
       "HousVacant               1.609686e+07\n",
       "NumInShelters            6.849843e+04\n",
       "RentHighQ                4.226112e+04\n",
       "RentMedian               3.139579e+04\n",
       "MedRent                  3.067083e+04\n",
       "RentLowQ                 2.186074e+04\n",
       "NumStreet                1.212955e+04\n",
       "RentQrange               7.669405e+03\n",
       "pctUrban                 1.977313e+03\n",
       "PctBornSameState         2.888412e+02\n",
       "PctImmigRec10            2.599518e+02\n",
       "PctSpeakEnglOnly         2.183749e+02\n",
       "PctImmigRec8             2.019611e+02\n",
       "PctPersOwnOccup          1.964882e+02\n",
       "PctHousLess3BR           1.941096e+02\n",
       "PctVacMore6Mos           1.935699e+02\n",
       "PctHousOwnOcc            1.921186e+02\n",
       "pctWInvInc               1.653219e+02\n",
       "                             ...     \n",
       "PctHousOccup             3.014799e+01\n",
       "agePct65up               2.299137e+01\n",
       "pctWRetire               2.119198e+01\n",
       "pctWPubAsst              2.061301e+01\n",
       "agePct12t21              2.039814e+01\n",
       "PctNotSpeakEnglWell      1.901154e+01\n",
       "PctRecImmig10            1.892474e+01\n",
       "PctHousNoPhone           1.694739e+01\n",
       "PctLargHouseFam          1.527843e+01\n",
       "PctVacantBoarded         1.163982e+01\n",
       "PctRecImmig8             1.140737e+01\n",
       "PctLargHouseOccup        1.076456e+01\n",
       "FemalePctDiv             1.071264e+01\n",
       "PctKidsBornNeverMar      9.174823e+00\n",
       "TotalPctDiv              8.991746e+00\n",
       "MedOwnCostPctInc         8.781905e+00\n",
       "MedRentPctHousInc        8.365727e+00\n",
       "PctUnemployed            7.808133e+00\n",
       "MalePctDivorce           7.758777e+00\n",
       "PctRecImmig5             6.345126e+00\n",
       "PctRecentImmig           2.636934e+00\n",
       "MedOwnCostPctIncNoMtg    2.156507e+00\n",
       "pctWFarmSelf             4.950695e-01\n",
       "MedNumBR                 2.668708e-01\n",
       "PctWOFullPlumb           1.990165e-01\n",
       "PersPerRentOccHous       1.572358e-01\n",
       "householdsize            1.115701e-01\n",
       "PersPerOccupHous         1.040479e-01\n",
       "PersPerOwnOccHous        9.232339e-02\n",
       "PersPerFam               6.185873e-02\n",
       "Length: 88, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_variance = X_train.var().sort_values(ascending=False)\n",
    "features_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pctUrban                 0.197731\n",
       "RentHighQ                0.063005\n",
       "MedYrHousBuilt           0.054831\n",
       "OwnOccHiQuart            0.048807\n",
       "MedRent                  0.046863\n",
       "RentMedian               0.040450\n",
       "PctBornSameState         0.039707\n",
       "PctHousNoPhone           0.036663\n",
       "PctPersOwnOccup          0.035128\n",
       "PctHousOwnOcc            0.034402\n",
       "TotalPctDiv              0.033926\n",
       "PctImmigRec10            0.033568\n",
       "PctBSorMore              0.032818\n",
       "OwnOccMedVal             0.032568\n",
       "PctVacMore6Mos           0.032530\n",
       "PctKids2Par              0.031951\n",
       "PctPopUnderPov           0.031801\n",
       "PctImmigRec8             0.030927\n",
       "PctYoungKids2Par         0.030667\n",
       "MalePctDivorce           0.030384\n",
       "PctEmplManu              0.029901\n",
       "pctWPubAsst              0.029756\n",
       "MedNumBR                 0.029652\n",
       "PctOccupMgmtProf         0.028443\n",
       "MedOwnCostPctInc         0.028351\n",
       "PctFam2Par               0.028349\n",
       "PctNotHSGrad             0.027298\n",
       "RentLowQ                 0.026869\n",
       "FemalePctDiv             0.026489\n",
       "PctImmigRec5             0.026074\n",
       "                           ...   \n",
       "medIncome                0.014829\n",
       "OwnOccQrange             0.014403\n",
       "PctNotSpeakEnglWell      0.014333\n",
       "PersPerOccupHous         0.013758\n",
       "PersPerFam               0.013507\n",
       "householdsize            0.013175\n",
       "PctLargHouseOccup        0.012703\n",
       "pctWFarmSelf             0.012395\n",
       "MedOwnCostPctIncNoMtg    0.012191\n",
       "perCapInc                0.012054\n",
       "PctSameState85           0.012045\n",
       "PersPerOwnOccHous        0.012032\n",
       "pctWRetire               0.011985\n",
       "RentQrange               0.011894\n",
       "agePct12t29              0.010796\n",
       "agePct65up               0.010638\n",
       "PctPersDenseHous         0.010563\n",
       "agePct16t24              0.010450\n",
       "agePct12t21              0.009548\n",
       "PctHousOccup             0.007963\n",
       "PctVacantBoarded         0.007315\n",
       "PctWOFullPlumb           0.007005\n",
       "NumInShelters            0.003125\n",
       "HousVacant               0.002364\n",
       "numbUrban                0.001265\n",
       "NumStreet                0.001255\n",
       "NumKidsBornNeverMar      0.001249\n",
       "population               0.001243\n",
       "NumUnderPov              0.001160\n",
       "NumImmig                 0.000770\n",
       "Length: 88, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_variance = X_train_scaled.var().sort_values(ascending=False)\n",
    "features_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем удалить признаки с самой низкой дисперсией и посмотреть, как изменится качество. В `sklearn` есть специальный инструмент для такого наивного отбора признаков. Стоит ли нормализовать перед этим признаки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1495, 76)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# можно убрать все признаки, вариативность которых меньше заданного значения\n",
    "vs_transformer = VarianceThreshold(0.01)\n",
    "X_train_var = pd.DataFrame(data=vs_transformer.fit_transform(X_train_scaled), columns=X_train_scaled.columns[vs_transformer.get_support()])\n",
    "X_test_var = pd.DataFrame(data=vs_transformer.transform(X_test_scaled), columns=X_test_scaled.columns[vs_transformer.get_support()])\n",
    "\n",
    "X_train_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 125706.38916046255\n",
      "Test: 149123.25580684416\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 136186.7830145162\n",
      "Test: 152046.21566890887\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_var,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_var))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_var))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно выбрать k признаков, которые дают наиболее высокие значения корреляции с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Выбираем 15 лучших признаков\n",
    "sb = SelectKBest(f_regression, k=15)\n",
    "\n",
    "X_train_kbest = pd.DataFrame(data=sb.fit_transform(X_train_var, y_train), columns=X_train_var.columns[sb.get_support()])\n",
    "X_test_kbest = pd.DataFrame(data=sb.transform(X_test_var), columns=X_test_var.columns[sb.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 147378.18578795987\n",
      "Test: 156005.780358924\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 158023.13299833486\n",
      "Test: 166680.07085931386\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_kbest,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_kbest))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_kbest))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно выбрать самые значимые признаки с точки зрения регрессии с $L_1$-регуляризацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1495, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lasso = Lasso(5.0)\n",
    "l1_select = SelectFromModel(lasso)\n",
    "\n",
    "X_train_l1 = pd.DataFrame(data=l1_select.fit_transform(X_train_var, y_train), columns=X_train_var.columns[l1_select.get_support()])\n",
    "X_test_l1 = pd.DataFrame(data=l1_select.transform(X_test_var), columns=X_test_var.columns[l1_select.get_support()])\n",
    "\n",
    "X_train_l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 140757.45879349476\n",
      "Test: 153086.92726760302\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, lr.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, lr.predict(X_test_l1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 143263.16845636512\n",
      "Test: 157553.36533174032\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(5.0).fit(X_train_l1,y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, ridge.predict(X_train_l1))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, ridge.predict(X_test_l1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно сделать все вышеописанное сразу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'variance': VarianceThreshold(threshold=0.01),\n",
       " 'selection': SelectFromModel(estimator=Lasso(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       "         max_features=None, norm_order=1, prefit=False, threshold=None),\n",
       " 'regressor': Ridge(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=False, random_state=None, solver='auto', tol=0.001)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('variance', VarianceThreshold(0.01)),\n",
    "    ('selection', SelectFromModel(Lasso(5.0))),\n",
    "    ('regressor', Ridge(5.0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 143263.16845636512\n",
      "Test: 157553.36533174032\n"
     ]
    }
   ],
   "source": [
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также настраивать параметры с помощью `GridSearch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "  ('variance', VarianceThreshold(threshold=0.01)),\n",
       "  ('selection',\n",
       "   SelectFromModel(estimator=Lasso(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False),\n",
       "           max_features=None, norm_order=1, prefit=False, threshold=None)),\n",
       "  ('regressor',\n",
       "   Ridge(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001))],\n",
       " 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'variance': VarianceThreshold(threshold=0.01),\n",
       " 'selection': SelectFromModel(estimator=Lasso(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       "         max_features=None, norm_order=1, prefit=False, threshold=None),\n",
       " 'regressor': Ridge(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__feature_range': (0, 1),\n",
       " 'variance__threshold': 0.01,\n",
       " 'selection__estimator__alpha': 5.0,\n",
       " 'selection__estimator__copy_X': True,\n",
       " 'selection__estimator__fit_intercept': True,\n",
       " 'selection__estimator__max_iter': 1000,\n",
       " 'selection__estimator__normalize': False,\n",
       " 'selection__estimator__positive': False,\n",
       " 'selection__estimator__precompute': False,\n",
       " 'selection__estimator__random_state': None,\n",
       " 'selection__estimator__selection': 'cyclic',\n",
       " 'selection__estimator__tol': 0.0001,\n",
       " 'selection__estimator__warm_start': False,\n",
       " 'selection__estimator': Lasso(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'selection__max_features': None,\n",
       " 'selection__norm_order': 1,\n",
       " 'selection__prefit': False,\n",
       " 'selection__threshold': None,\n",
       " 'regressor__alpha': 5.0,\n",
       " 'regressor__copy_X': True,\n",
       " 'regressor__fit_intercept': True,\n",
       " 'regressor__max_iter': None,\n",
       " 'regressor__normalize': False,\n",
       " 'regressor__random_state': None,\n",
       " 'regressor__solver': 'auto',\n",
       " 'regressor__tol': 0.001}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('variance', VarianceThreshold(threshold=0.01)), ('selection', SelectFromModel(estimator=Lasso(alpha=5.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   sele...it_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=False, n_jobs=None,\n",
       "       param_grid={'variance__threshold': [0.005, 0.0075, 0.009, 0.01, 0.011, 0.012], 'selection__estimator__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0], 'regressor__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'variance__threshold': [0.005, 0.0075, 0.009, 0.01, 0.011, 0.012],\n",
    "    'selection__estimator__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    'regressor__alpha': [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0]\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, param_grid, iid=False, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'variance': VarianceThreshold(threshold=0.01),\n",
       " 'selection': SelectFromModel(estimator=Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       "         max_features=None, norm_order=1, prefit=False, threshold=None),\n",
       " 'regressor': Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=False, random_state=None, solver='auto', tol=0.001)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_best = grid_search.best_estimator_\n",
    "pipe_best.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 128441.16453337156\n",
      "Test: 147186.92249142195\n"
     ]
    }
   ],
   "source": [
    "pipe_best.fit(X_train, y_train)\n",
    "print (\"Train: {}\".format(mean_squared_error(y_train, pipe_best.predict(X_train))))\n",
    "print (\"Test: {}\".format(mean_squared_error(y_test, pipe_best.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
